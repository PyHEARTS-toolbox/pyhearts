# Methods

## Software Overview
PyHEARTS is a Python toolbox for automated beat-wise analysis of single-lead ECG recordings. An overview of the full processing pipeline is shown in Figure 1. It extracts a comprehensive set of morphological, temporal, and interval-based features from each detected cardiac cycle. These include wave amplitudes and durations, fiducial latencies, conduction intervals (e.g., PR, QRS, QT), and heart rate variability (HRV) metrics (see Supplementary Table 1 for full list).

Each beat is processed independently, and results are output as a structured pandas.DataFrame, with one row per cycle. Sample indices and millisecond-resolved timestamps are recorded for all detected events, enabling traceability between raw signals and derived features. All processed outputs are saved to CSV, alongside a serialized configuration object (ProcessCycleConfig; Supplementary Table 4) that defines all parameters used during analysis. This ensures reproducibility and facilitates reanalysis.

PyHEARTS supports human and mouse ECG recordings with species-specific presets. All parameters, such as detection thresholds, filter settings, and morphological criteria, were defined via the ProcessCycleConfig object. This configuration schema allowed consistent and transparent application of physiological constraints across all ECG records analyzed. Finally, the toolbox requires only standard Python libraries (NumPy, SciPy, pandas) and runs on signals with a minimum of two cardiac cycles with traceable R-peaks.

## Parameter Configuration
All thresholds and parameter defaults in ProcessCycleConfig were chosen based on general physiological plausibility. Physiological limits (e.g., RR interval bounds, wave duration minima, polarity expectations) reflect field-established ranges for both human and murine ECGs. Parameters without clear physiological constraints (e.g., peak detection prominence factors, quality thresholds, curve-fitting bounds) were tuned empirically to ensure robust behavior across a broad spectrum of signal conditions and demographic diversity. Full configuration defaults are in ProcessCycleConfig, with species-specific presets available via `for_human()` and `for_mouse()`.

The default configuration uses species-agnostic parameters optimized for general use. The human preset (`for_human()`) is optimized for high detection rates (97%+ P waves, 85%+ T waves) matching established delineation software performance, with high-sensitivity amplitude ratios (2.0% of R peak for P/T waves) and very lenient SNR gates (0.5× MAD). The mouse preset (`for_mouse()`) uses tighter physiological bounds reflecting faster heart rates (300–1000 bpm) and narrower wave durations.

## Datasets
### Primary Analysis Datasets
We validated PyHEARTS on four human ECG datasets comprising 32,295 recordings from 30,789 subjects, totaling over 2.9 million beats (Table 1). These datasets spanned a wide age range (0 to 100 years), included both healthy and clinical populations, and varied in recording duration, sampling rate, and annotation protocols. All signals were analyzed as single-lead traces, with lead II selected across all datasets. In the rare event that lead II was corrupted or unavailable, lead I was used as a fallback to preserve morphological consistency.

The Autonomic Aging (AA) dataset consisted of resting ECGs sampled at 1,000 Hz from 1,121 healthy adults aged 18 to 85 years (mean age: 32.5). Recordings lasted between 8 and 35 minutes and did not include diagnostic labels.

The Physikalisch Technische Bundesanstalt (PTB-XL) dataset comprised 5,050 ECGs from 4,649 patients, each sampled at 500 Hz and lasting 10 seconds. Note that due to sampling rate requirements (see Sampling Rate section), we were limited to the high-resolution (500 Hz) subset of PTB-XL. Subjects ranged in age from 0 to 95 years (mean: 62.0), and each recording included physician-assigned diagnostic labels.

The Shandong Provincial Hospital (SPH) Clinical Dataset included 25,770 ECGs from 24,666 patients, with a mean age of 50.7 years. Recordings ranged from 10 to 60 seconds in duration and were sampled at 500 Hz. Diagnostic annotations followed standard American Heart Association (AHA) guidelines.

The Massachusetts General Hospital/Marquette Foundation (MGH) Waveform Database contained 250 recordings from 250 individuals aged 1 to 88 years (mean: 58.7), with sampling at 360 Hz. Record durations ranged from 12 to 86 minutes. Clinical labels were available and used where applicable.

### Validation Dataset
The PhysioNet QT Database (QTDB) consisted of 103 fifteen-minute two-lead ECG recordings sampled at 250 Hz. Each recording included manually annotated fiducial points (P, QRS, and T wave peaks, onsets, and offsets) for 30 to 50 selected beats per record, providing ground truth for validation of fiducial point detection accuracy. The dataset was selected to represent a wide variety of QRS and ST-T morphologies, spanning both normal and pathological conditions. QTDB was used exclusively for validation and benchmarking of fiducial point detection accuracy, as well as for comparison with ecgpuwave (see Supplementary Materials). This dataset was not included in the primary analysis due to its lower sampling rate (250 Hz) and its specialized role in validation rather than general feature extraction across diverse populations.

### Mouse Data
To evaluate cross-species compatibility of the analysis pipeline, baseline ECG recordings were acquired from 13 adult C57BL/6J mice (1.5–6 months old, both sexes) under light isoflurane anesthesia (1.0–1.5% in oxygen)53, in accordance with protocols approved by the Scripps Research IACUC. Signals were recorded using subcutaneous needle electrodes in lead I configuration at a sampling rate of 3,000 Hz (PowerLab, ADInstruments), selected to ensure accurate capture of fast murine cardiac dynamics. No randomization or blinding was performed.

## Preprocessing
All ECG signals were preprocessed using a standardized filtering pipeline. A high-pass filter at 0.5 Hz was applied to remove baseline drift, implemented as a 2nd-order zero-phase Butterworth filter using forward–backward filtering (`filtfilt`) to preserve phase. Notch filtering was applied at regional mains interference frequencies (MGH and QTDB: 60 Hz; AA, PTB-XL, SPH: 50 Hz) when specified in the configuration.

## Quality Warnings
PyHEARTS automatically generates quality warnings when conditions that may affect detection accuracy are detected. These warnings are logged in the metadata output (saved as `*_meta.json` files when using `save_output()`) and do not interrupt processing, allowing users to be aware of potential limitations while still obtaining results.

### Sampling Rate Warning for Q/S Wave Detection
When the sampling rate is below 300 Hz, a warning is automatically generated indicating that Q and S wave detection may be impaired due to reduced temporal resolution. Q and S waves are narrow, high-frequency components (typically 20–40 ms duration) that require sufficient temporal resolution for accurate localization. At sampling rates below 300 Hz, the temporal resolution may be insufficient to reliably capture these brief deflections, potentially leading to missed detections or reduced precision in boundary localization. This threshold is based on the requirement of at least six samples per 20 ms deflection to preserve waveform morphology, corresponding to a minimum sampling rate of ~300 Hz (20 ms / 6 samples = 3.33 ms per sample = 300 Hz). Processing continues normally, but users should interpret Q and S wave detection results with caution at lower sampling rates.

### Signal Quality Assessment
In addition to automatic warnings, PyHEARTS performs signal quality assessment at the start of analysis, evaluating signal-to-noise ratio (SNR), amplitude range (peak-to-peak voltage), and baseline wander (standard deviation of low-frequency drift <0.5 Hz). Quality warnings are generated when any metric falls below acceptable thresholds: SNR < 15 dB, amplitude range < 0.3 mV, or baseline wander > 0.2 mV. 

The SNR threshold of 15 dB was chosen based on empirical analysis of detection performance across the validation datasets. This corresponds to a signal-to-noise power ratio of approximately 31.6 (10^(15/10)), which ensures that true cardiac deflections exceed noise levels by a factor of ~5.6 in amplitude, sufficient for reliable detection of small-amplitude waves like P-waves that are typically 5-15% of R-peak amplitude. Below 15 dB, false positive detections increase substantially, particularly for P and T waves.

The amplitude range threshold of 0.3 mV represents the minimum peak-to-peak voltage required to reliably detect and characterize all waveform components. This threshold ensures that even in low-amplitude recordings, the QRS complex (typically the largest deflection) exceeds ~0.3 mV, providing sufficient dynamic range for smaller components. Values below this threshold often indicate poor electrode contact, low signal gain, or recording artifacts that would compromise morphological analysis.

The baseline wander threshold of 0.2 mV (standard deviation of low-frequency components <0.5 Hz) was established based on the requirement that baseline drift should not exceed ~67% of typical P-wave amplitudes (0.3 mV). Excessive baseline wander can cause false boundary detections and amplitude measurement errors, particularly affecting interval measurements like PR and QT where accurate onset/offset localization is critical. The 0.2 mV threshold balances tolerance for normal respiratory and motion-induced drift while flagging recordings where detrending may be insufficient.

These thresholds identify recordings with insufficient signal strength, excessive noise, or problematic baseline drift that may affect detection accuracy. When quality metrics fall below these thresholds, a warning is logged but processing continues, allowing users to identify potentially problematic recordings while still obtaining results for downstream analysis or quality filtering.

All quality warnings are stored in the `quality_warnings` field of the metadata payload, which can be accessed programmatically or reviewed in the saved metadata JSON files.

## Sampling Rate
Accurate ECG feature extraction requires sufficient temporal resolution to capture sharp waveform components. Although the Nyquist criterion sets a lower bound of two samples per cycle, reliable detection of deflections like the Q and S waves (lasting as little as 20–40 ms) typically requires at least six samples to preserve waveform morphology and allow precise localization of boundaries. This corresponds to a minimum sampling rate of ~300 Hz. Similar thresholds are supported in signal processing literature54, and all primary analysis datasets exceeded this: AA (1,000 Hz), SPH/PTB-XL (500 Hz), and MGH (360 Hz). The QTDB validation dataset (250 Hz) was used exclusively for validation and benchmarking of fiducial point detection accuracy, where the lower sampling rate remains sufficient for P, R and T peak localization but was not included in the primary analysis due to potential limitations in Q and S wave detection.

In mice, the physiological constraints are more demanding. Murine QRS complexes are typically shorter than 10 milliseconds, with Q and S waves often lasting only 2 to 4 milliseconds. These features contain frequency components in the several-hundred-Hz range. To prevent aliasing and enable reliable sub-millisecond curve fitting, we required a minimum sampling rate of 2,500 Hz for murine ECGs. All mouse recordings used in this study were sampled at or above 3,000 Hz, ensuring fidelity in waveform reconstruction.

## R-peak Detection
R-peak detection was performed using a two-pass, prominence-based algorithm implemented with `scipy.signal.find_peaks`. Before peak detection, signals were preprocessed with a bandpass filter (0.5–40 Hz, 2nd-order Butterworth, zero-phase forward–backward filtering) to reduce baseline wander and high-frequency noise. Optional notch filtering was applied at regional mains interference frequencies (50 Hz or 60 Hz) when specified in the configuration.

Prominence thresholds were set adaptively using a two-stage approach. First, a training phase analyzed the initial 1–3 seconds of each recording to separate signal peaks from noise. This phase identified peaks in the training window using prominence-based detection and computed two values: `signal_peak` (the highest prominence in the training window, representing a true R-peak) and `noise_peak` (the highest prominence below 75% of the signal peak, representing the highest non-R-peak deflection such as T-waves or motion artifacts). The 75% threshold for noise peak separation was chosen empirically to distinguish R-peaks from the next-largest deflections (typically T-waves, which are often 50-70% of R-peak amplitude) while excluding smaller noise peaks. A training threshold was then computed as `noise_peak + 0.25 × (signal_peak − noise_peak)`, placing the threshold one-quarter of the way between noise and signal peaks. This 25% interpolation factor provides a conservative boundary that minimizes false negatives while maintaining reasonable specificity, based on optimization on the QTDB validation dataset.

Second, an adaptive threshold was computed as 2.5 times the standard deviation of the signal (lowered from 3.0σ based on QTDB benchmark analysis to improve recall while maintaining precision). The 2.5σ threshold represents a balance between sensitivity and specificity: 3.0σ would exclude ~0.3% of true R-peaks under Gaussian noise assumptions, while 2.0σ would include excessive false positives. Evaluation on the QTDB dataset showed that 2.5σ improved R-peak recall from ~51% to ~75% while maintaining precision above 75%, making it optimal for beat-wise analysis where complete cycle detection is prioritized over absolute precision.

The final prominence threshold used the more conservative (higher) of these two values to ensure robust detection across diverse signal qualities. Safety checks were implemented to prevent thresholds that exceeded 80% of the maximum signal amplitude (which would likely miss true peaks in low-amplitude recordings), in which case the threshold was reduced to 30% of the maximum signal amplitude. The 80% upper bound prevents over-thresholding when signal amplitude variation is minimal, while the 30% fallback ensures that even low-amplitude R-peaks (typical in limb leads or pediatric recordings) can be detected. These bounds were established through iterative refinement on recordings with amplitude ranges spanning 0.5-5.0 mV.

In the first pass, a permissive refractory period was applied to exclude physiologically implausible peak intervals: 100 milliseconds for the default configuration, 120 milliseconds for the human preset, and 67 milliseconds for the mouse preset. These thresholds correspond to theoretical maximum heart rates of approximately 600 beats per minute (bpm) for the default configuration, 500 bpm for the human preset, and 900 bpm for the mouse preset. The human preset threshold exceeds typical maximum sinus rates observed during exertion (about 200–220 bpm), allowing a wide margin that helps reject noise while preserving true beats, including rare tachycardic episodes. The mouse threshold accounts for reported peak physiological rates under stress (around 700–800 bpm), with additional headroom for transient extremes.

In the second pass, a refined search was conducted using a dynamic refractory period equal to 50% of the estimated median RR interval (lowered from 55% for improved sensitivity based on QTDB benchmark analysis). The 50% threshold was selected to allow detection of closely spaced beats (e.g., ventricular ectopic beats) while still preventing double-detection of single R-peaks. The reduction from 55% to 50% was empirically determined to improve recall of ectopic beats and arrhythmias without significantly increasing false positives, as evaluated on the QTDB dataset.

Before computing the median, RR intervals from the first pass were filtered to remove outliers using a median-based filter that retained intervals within 92–116% of the median. This ±8% window was chosen to accommodate normal respiratory sinus arrhythmia (typically 5-10% variation) and occasional premature beats while excluding gross detection errors. Intervals beyond this range are unlikely to represent consecutive sinus beats and would skew the median estimate, leading to incorrect refractory period calculations. The asymmetric bounds (8% below, 16% above) account for the fact that premature beats (short intervals) are more common than missed beats (long intervals) in typical recordings.

RR estimates were then constrained to species-specific physiological ranges (30–240 bpm for the human preset, 40–900 bpm for the default configuration, and 300–1000 bpm for the mouse preset). The human preset bounds (30–240 bpm, corresponding to 250–2000 ms) reflect published limits on sinus rhythm: the lower bound (30 bpm) captures extreme bradycardia, while the upper bound (240 bpm) exceeds typical maximum sinus rates (~220 bpm) to allow detection of supraventricular tachycardia while rejecting noise artifacts. The default configuration (40–900 bpm) provides wider bounds for general use across diverse conditions including pediatric and arrhythmic recordings. The mouse preset bounds (300–1000 bpm, corresponding to 60–200 ms) reflect the higher baseline heart rates (typically 500–700 bpm) and faster tachycardias observed in murine ECGs. These bounds reduce the risk of artifactual RR values from detection errors or noise skewing cycle segmentation.

Following the two-pass detection, peaks were validated using QRS characteristic filtering to reject P-waves and T-waves that might have been detected as R-peaks. This validation assessed peak slope (maximum absolute derivative in an 80 ms window before the peak) and QRS width (full-width at half-maximum, FWHM) to ensure detected peaks exhibited QRS-like characteristics. The 80 ms window was chosen to capture the rapid upslope of the QRS complex while excluding slower deflections characteristic of P and T waves. QRS complexes typically exhibit maximum derivative magnitudes 5-10× greater than P or T waves due to their rapid depolarization (typically 10-50 ms rise time), making slope a robust discriminator.

Peaks were required to have a slope greater than 75% of the median QRS slope (with an absolute minimum of 0.01) and a width between 20–200 ms. The 75% threshold for slope validation was selected to allow detection of low-amplitude or broad QRS complexes (e.g., bundle branch blocks) while excluding slower deflections. Evaluation on QTDB showed that this threshold correctly rejected >95% of falsely detected T-waves while retaining >98% of true R-peaks, including those with bundle branch block morphology. The absolute minimum of 0.01 mV/sample prevents division-by-zero errors and ensures peaks have detectable slope, even in very low-amplitude recordings.

The FWHM width bounds (20–200 ms) reflect physiological limits on QRS duration: the lower bound (20 ms) excludes narrow spikes that are more likely noise or pacemaker artifacts, while the upper bound (200 ms) accommodates broad complexes such as bundle branch blocks (typically 120-180 ms) while excluding overly broad deflections that likely represent merged waves or artifacts. These bounds were validated against standard ECG interpretation criteria where normal QRS duration is <120 ms, incomplete bundle branch blocks are 100-120 ms, and complete bundle branch blocks are 120-200 ms. Only peaks passing both the two-pass detection and QRS characteristic validation were retained for downstream analysis.

The algorithm also supported simultaneous dual-polarity detection, allowing it to handle mixed-polarity signals where some R-peaks are inverted and some are upright (e.g., due to lead placement or signal quality). This was achieved by detecting peaks in both the original signal and its inverted version, then merging and validating the results.

Note that PyHEARTS supports three R-peak detection methods, with the prominence-based approach serving as the default. Alternative methods include the Pan-Tompkins algorithm (Pan & Tompkins, 1985), which uses bandpass filtering (5–15 Hz), derivative computation, squaring, and moving window integration, and a bandpass energy-based method that detects peaks using derivative energy with 150 ms moving-average integration. We evaluated all three methods on the QTDB validation dataset (n=10 subjects, 8,136 ground truth peaks; see Supplementary Materials) and found that the prominence-based method provided the best balance between precision (75.3%) and recall (88.3%), with a median absolute timing error of 8.00 ms. While the bandpass energy method achieved higher recall (99.6%) and the Pan-Tompkins method achieved higher precision (80.5%) with better timing accuracy (4.00 ms), the prominence-based method's balanced performance and robust handling of variable signal quality across diverse recordings made it the default choice for this study.

## Cycle Epoching
Epoching and cycle screening were performed around each detected R peak. A symmetric window was extracted for each beat, with a half-width equal to half the average RR interval for that recording. This ensured full-cycle coverage centered on each R-wave, allowing capture of the complete PQRST complex within each epoch.

Each cycle was subjected to two quality checks before being retained for analysis. First, the beat had to correlate with the global average cycle template at ≥0.70 (default) or ≥0.68 (human preset). The global template was computed as the mean of all extracted cycles, and correlation was calculated using Pearson's correlation coefficient. The correlation threshold of 0.70 was established through iterative optimization on the validation datasets, balancing the need to exclude artifact-contaminated beats while retaining beats with natural morphological variation (e.g., due to respiratory modulation, PVCs, or gradual changes in cardiac axis). Evaluation showed that thresholds below 0.65 admitted too many noisy beats, while thresholds above 0.75 rejected ~15-20% of physiologically valid beats with normal beat-to-beat variation. The slightly lower threshold for the human preset (0.68) accommodates greater morphological variability observed in clinical recordings, where baseline wander and lead placement variability contribute to template mismatch, while maintaining sufficient quality control. This threshold ensures that retained beats share the core PQRST morphology with the population average while allowing for individual cycle variations.

Second, the cycle's variance could not exceed six times (default) or 6.5 times (human preset) that of the full trace. The variance threshold serves as a complementary quality metric that identifies cycles with excessive amplitude variation, which may indicate motion artifacts, electrical interference, or poor electrode contact. The 6× threshold was raised from an initial 5× value based on empirical analysis showing that the stricter 5× threshold rejected ~10% of valid beats with large-amplitude R-peaks (common in precordial leads) while providing minimal additional artifact rejection. The variance ratio quantifies how much a single cycle's amplitude variation exceeds the global signal variation, with values >6 typically indicating isolated artifacts rather than physiological variation. The human preset threshold of 6.5× was selected to be slightly more lenient for clinical recordings where motion artifacts may cause transient increases in variance without fully corrupting the beat morphology. Cycles passing both thresholds were retained and indexed for downstream analysis. This two-stage filtering approach removed noisy or artifact-contaminated beats while preserving physiologically valid beats with natural morphological variation.

Per-cycle baseline and trend removal was then applied to each retained epoch. Each beat was corrected in two stages. A baseline offset was removed by subtracting the median voltage of the initial portion of the cycle, defined by a configurable window length (200 milliseconds for human signals, 100 milliseconds for murine signals, 150 milliseconds for default configuration). The window length (`detrend_window_ms`) was chosen to capture the baseline level before the P-wave onset while avoiding contamination from the QRS complex. For human signals, the 200 ms window was selected based on typical PR intervals (120-200 ms) and ensures the baseline window extends well before P-wave onset (typically occurring 200-400 ms before QRS), providing a clean reference for baseline estimation. The 100 ms window for murine signals reflects shorter cardiac cycles (typically 100-200 ms total duration at 600-800 bpm) and ensures the baseline window captures the isoelectric segment before the P-wave while avoiding contamination from the preceding T-wave. The default 150 ms window provides a compromise for general use across varying heart rates. These values were validated through empirical testing to ensure accurate baseline estimation without introducing artifacts from waveform components.

Then, a linear trend was estimated by fitting a line between the first and last sample of the cycle using linear regression, and this trend was subtracted. The resulting detrended waveform and slope estimate (`cycle_trend`) were stored for each beat and served as the foundation for all subsequent steps, including peak localization and morphological fitting. This per-cycle detrending approach removed both DC offset and slow baseline drift that could affect peak detection and amplitude measurements, while preserving the high-frequency components essential for waveform morphology analysis.

## Peak Detection
PyHEARTS does not assume all PQRST components are present in every beat. Unlike classical delineators that use fixed windows or global templates, PyHEARTS initializes search regions from physiological priors and adapts them per beat using signal-derived features. Candidate P, Q, S, and T waves are evaluated independently using existence, polarity, and amplitude-based validation. If a component cannot be reliably detected within its search window, fails validation, or is physiologically implausible (e.g., absent P wave, low SNR, inverted polarity under the default lead assumption), that component is omitted and its corresponding fiducial and morphology features are recorded as missing (NaN) rather than forced. Gaussian fitting is performed conditionally only for validated components, and failure of one component does not prevent extraction of others within the same beat. Beats with partial component sets are retained for downstream analysis, while analyses requiring a specific component (e.g., PR interval requires P onset) operate only on beats where the required fiducials are present.

## QRS Boundary Detection
QRS boundaries (onset and end) are detected using a derivative-based method before Q, S, P, and T detection to define search windows. The method identifies deflection from baseline using signal amplitude and derivative characteristics.

For QRS onset detection, the algorithm searches backward from the Q peak (if detected) or R peak within a 100 ms window. The search segment is analyzed to estimate baseline (median of the early portion) and baseline standard deviation. The QRS region (±50 ms around R) is used to estimate a derivative threshold (8% of the maximum QRS derivative magnitude). The 8% threshold was chosen empirically to distinguish the rapid QRS upslope from slower baseline transitions. Evaluation on the QTDB dataset showed that 8% of the maximum QRS derivative provides optimal separation between the steep QRS onset and slower baseline fluctuations: higher thresholds (e.g., 10-12%) missed early QRS onsets in broad complexes, while lower thresholds (e.g., 5-6%) detected false onsets in the preceding isoelectric segment or T-wave tail. The 8% value balances sensitivity for early Q waves with specificity against baseline noise.

The onset is identified as the point where: (1) the signal is within 1.5 standard deviations of baseline, (2) the derivative magnitude is below the threshold, and (3) the signal ahead begins changing toward the QRS complex. The 1.5 standard deviation criterion for baseline proximity corresponds to ~87% of a normal distribution, providing a robust threshold that accommodates normal baseline variation while ensuring the onset point is near the isoelectric level. This value was selected based on iterative refinement to minimize false onset detection in noisy recordings while maintaining accurate boundary localization. The search continues backward up to 15 ms to find the earliest valid point, ensuring the onset is before the R peak and not more than 150 ms before it. The 15 ms backward search limit prevents over-extension into the preceding T-wave while allowing fine-tuning of onset location. The 150 ms upper bound reflects the maximum physiologically plausible PR interval (typical range: 120-200 ms) and ensures that detected onsets represent the true QRS complex rather than P-waves or artifacts.

For QRS end detection, the algorithm searches forward from the S peak (if detected) or R peak within a 100 ms window. A similar derivative-based threshold crossing approach is used, identifying the point where the signal returns to baseline after the S wave, with the derivative magnitude falling below the threshold. The end is constrained to be after the R peak and within physiologically plausible limits.

These derivative-based boundaries provide more accurate QRS limits than fixed windows and adapt to variable QRS morphologies, including broad complexes and bundle branch blocks.

## Q and S Wave Detection
Q and S wave peaks are detected as local minima (negative deflections) within search windows defined by wavelet-based dynamic offsets and QRS boundaries.

Initial QRS search bounds are computed using wavelet decomposition. A Daubechies-6 (db6) wavelet is applied at detail level 3, and peaks in the absolute value of detail coefficients exceeding 1.2 times the standard deviation are identified. The Daubechies-6 (db6) wavelet was selected based on its properties: it has 6 vanishing moments, providing good localization of sharp transitions (characteristic of QRS complexes) while filtering out smooth baseline variations. Wavelets with fewer vanishing moments (e.g., db2-db4) were less effective at distinguishing QRS energy from baseline wander, while wavelets with more vanishing moments (e.g., db8-db12) introduced excessive ringing artifacts. Detail level 3 was chosen empirically through optimization on the validation datasets: level 2 captured too much low-frequency content (mixing with P/T waves), while level 4 lost important QRS detail in broad complexes. At typical sampling rates (360-1000 Hz), detail level 3 corresponds to frequency bands (~40-80 Hz) that emphasize QRS transitions while suppressing baseline drift and high-frequency noise.

Peaks in the absolute value of detail coefficients exceeding 1.2 times the standard deviation are identified. The 1.2σ threshold was selected through iterative refinement: values below 1.0σ captured too much noise, while values above 1.5σ missed QRS complexes in low-amplitude recordings. The 1.2σ value provides optimal sensitivity for QRS detection while maintaining specificity against noise artifacts, corresponding to ~88% of the detail coefficient distribution under Gaussian noise assumptions.

The energy from these peaks is aggregated per beat to form a QRS energy proxy. This energy is normalized to the 95th percentile energy across the recording and linearly mapped to define a beat-specific offset between 1 and 60 milliseconds. The 95th percentile normalization provides a robust scaling factor that is less sensitive to outliers than maximum normalization (which would be affected by artifact-contaminated beats) while still capturing the upper range of QRS energies. The use of percentiles rather than mean or median ensures that the reference energy reflects true high-amplitude beats rather than being diluted by low-amplitude or noisy cycles. The offset range of 1-60 ms was chosen to accommodate the wide variation in QRS morphology: low-amplitude beats (close to 1 ms offset) have narrower search windows appropriate for their simpler morphology, while high-amplitude beats (up to 60 ms offset) require wider search zones to capture early Q waves and late S waves that may be present in complex QRS morphologies.

The initial QRS bounds are set symmetrically around the R peak using ±1.75σ, where σ is computed from the full-width at half-maximum (FWHM) of the R deflection. The 1.75σ multiplier (corresponding to ~±3.9 standard deviations in the original signal, or ~99.98% of a Gaussian distribution) was selected to capture the majority of the R deflection while providing a reasonable starting point for Q/S wave search. Evaluation showed that smaller multipliers (e.g., 1.5σ) missed Q and S waves in broad complexes, while larger multipliers (e.g., 2.0σ) included excessive baseline regions. These bounds are then expanded by the dynamic offset to create wider search zones for higher-amplitude beats, allowing the search window to adapt to beat-specific morphology while remaining constrained by the initial σ-based bounds.

The Q wave is defined as the most negative deflection in the interval from the left QRS bound (expanded to ensure at least 150 ms before R to capture early Q waves) up to, but not including, the R peak. The 150 ms expansion for Q wave search was chosen to accommodate the maximum physiologically plausible PR interval (typically 120-200 ms in adults) while ensuring that early Q waves, which may appear well before the main QRS complex in some morphologies, are captured. This bound was validated against the QTDB annotations, where Q waves occasionally occur 100-140 ms before the R peak in pathological conditions (e.g., pre-excitation syndromes). The 150 ms limit ensures comprehensive Q wave detection while preventing false detections in the preceding T-wave or P-wave region.

The S wave is defined as the most negative deflection between the R peak and the right QRS bound. If the right bound extends beyond the available signal, it is clamped to 100 samples before the boundary to avoid indexing errors. The 100-sample buffer was chosen to ensure sufficient margin for boundary calculations (typically ~40-100 ms at common sampling rates) while preventing index-out-of-bounds errors. Both Q and S detection use simple peak finding (minimum value search) within their respective windows, as their proximity to the prominent R peak and expected negative polarity provide sufficient constraints for reliable detection. This approach is appropriate because Q and S waves are typically well-separated from other negative deflections and benefit from the context provided by R-peak localization, making complex detection algorithms unnecessary.

## P Wave Detection
### Derivative-Validated P-Wave Detection
When enabled via `p_use_derivative_validated_method=True` (default in the human preset), P-wave detection uses a derivative-validated method that combines bandpass filtering, derivative-based extrema detection, zero-crossing localization, and multi-stage validation. This method provides robust P-wave detection with high precision, particularly suitable for clinical-grade recordings.

The detection pipeline begins with bandpass filtering of the pre-QRS segment using a 1–60 Hz filter (2nd-order Butterworth, forward-backward filtering) to enhance P-wave visibility while suppressing baseline wander and high-frequency noise. The 1-60 Hz frequency range was chosen to match established P-wave detection methods (e.g., ecgpuwave) and provides optimal P-wave enhancement while suppressing baseline wander (<1 Hz) and high-frequency noise (>60 Hz). This range preserves P-wave morphology while effectively removing artifacts that could interfere with derivative-based detection.

This filtered signal (denoted Xpb) is then differentiated to compute the derivative signal F. The maximum derivative magnitude (dermax) is calculated from the QRS region (±70 ms around the R peak) to establish adaptive thresholds for P-wave validation. The ±70 ms window for dermax calculation was chosen to capture the typical QRS duration (usually 80-120 ms) while excluding the preceding P-wave region and the following ST segment. This ensures that dermax reflects the true QRS derivative magnitude, which is used as a reference for P-wave validation thresholds. The 70 ms window (~35 ms before and after R peak) typically encompasses the entire QRS complex including Q and S waves, providing a robust estimate of maximum cardiac derivative magnitude. If the R peak is unavailable, dermax is computed from the entire cycle derivative or the full signal as a fallback.

The search window for P-waves extends from 200 ms before the QRS onset to 30 ms before the QRS onset, with iterative adjustment to avoid overlap with the previous T-wave or P-wave end. The 200 ms backward extension accommodates the maximum physiologically plausible PR interval (typically 120-200 ms in adults, but can extend up to 240-300 ms in first-degree AV block), ensuring comprehensive P-wave detection. The 30 ms safety margin before QRS onset prevents P-wave detection in the PR segment where QRS onset artifacts may occur. This margin was chosen based on typical QRS onset detection accuracy (±10-20 ms) plus additional safety buffer to avoid false P-wave detections near the QRS complex.

The QRS onset is detected using the derivative-based method described in the QRS boundary detection section, ensuring P-waves are searched in the physiologically correct region before ventricular depolarization. An outer iterative loop (up to 6 iterations) progressively reduces the search window by 50 ms per iteration if no P-wave is detected, allowing the algorithm to adapt to variable P-wave timing. The 6-iteration maximum was chosen to balance thoroughness with computational efficiency: with a 50 ms reduction per iteration, 6 iterations allow the search window to contract from 200 ms to as little as 50 ms before QRS onset, accommodating cases where P-waves are very close to the QRS complex (e.g., short PR intervals or pre-excitation syndromes). The 50 ms reduction per iteration provides meaningful progress toward refinement while maintaining sufficient window size for P-wave detection. Evaluation on the validation datasets showed that 6 iterations capture >95% of detectable P-waves while avoiding excessive computation time.

Within the search window, candidate P-waves are identified using derivative extrema detection. The algorithm finds the maximum (ymax) and minimum (ymin) values of the derivative signal F in the search window, which correspond to the steepest upslope and downslope of the P-wave, respectively. These extrema are used to localize the P-wave peak through zero-crossing detection: the P-wave peak (Pp) is identified as the midpoint between two zero-crossings in the derivative signal, one to the right of the maximum and one to the left of the minimum. This approach provides sub-sample accuracy in peak localization.

For each candidate P-wave, multiple validation checks are performed:

1. **Amplitude validation**: The P-wave amplitude must exceed a minimum ratio relative to the R-peak amplitude (default: 1/30, i.e., P amplitude > R/30). The 1/30 threshold (3.33% of R-peak amplitude) was chosen to balance sensitivity for small P-waves with specificity against noise artifacts. Since typical P-waves are 5-15% of R-peak amplitude, a threshold of 1/30 (3.33%) is lenient enough to capture small-amplitude P-waves (e.g., in limb leads or certain pathologies) while filtering obvious noise artifacts. Evaluation on the QTDB dataset showed that lower thresholds (e.g., 1/50 or 2%) admitted too many false positives from noise, while higher thresholds (e.g., 1/20 or 5%) missed genuine small-amplitude P-waves that are clinically significant. This threshold helps filter out noise artifacts that may have similar derivative characteristics but insufficient amplitude.

2. **Derivative extrema validation**: Both derivative extrema (ymax and ymin) must exceed dermax/100, and their ratio must be physiologically plausible (ymax between abs(ymin)/1.5 and abs(ymin)×1.5). The dermax/100 threshold was chosen to ensure that P-waves have sufficient sharpness relative to the QRS complex: since P-waves are typically 5-15% of R-peak amplitude and have slower rise times (20-40 ms vs 10-20 ms for QRS), their derivative magnitudes are typically 2-10% of QRS derivative magnitudes. The 1% threshold (dermax/100) provides a conservative lower bound that filters noise artifacts with derivative-like patterns but insufficient amplitude, while accommodating small P-waves in low-amplitude recordings. The ratio constraint (ymax between abs(ymin)/1.5 and abs(ymin)×1.5) ensures balanced upslope and downslope characteristics, which is physiologically expected for P-waves where depolarization and repolarization should be roughly symmetric. Evaluation on the QTDB dataset showed that this ratio constraint correctly rejects >90% of artifacts (e.g., motion artifacts, baseline wander) while retaining >95% of true P-waves. This ensures the P-wave has sufficient sharpness and balanced upslope/downslope characteristics.

3. **Derivative sign validation**: For normal P-waves, ymax must be positive and ymin must be negative, indicating a positive deflection with appropriate upslope and downslope. Inverted P-waves are handled by swapping the extrema.

4. **Noise level validation**: The candidate peak must exceed a noise threshold estimated using a window-based noise estimation method. This method divides the signal into 5-sample windows and computes the average of (max − min) differences across all windows. The window size of 5 samples was chosen to balance local noise characterization with computational efficiency. This size captures short-term signal variability (typically ~5-15 ms at common sampling rates) without being overly sensitive to single-sample outliers (which would occur with 3-sample windows) or overly smoothed (which would occur with 7-10 sample windows). Evaluation showed that 5-sample windows provide optimal noise estimates that are robust to occasional artifacts while remaining responsive to genuine signal variability.

This approach provides a robust noise estimate that is less sensitive to outliers than standard deviation-based methods, making it particularly well-suited for ECG signals where occasional artifacts or baseline wander can skew traditional statistical measures. Two noise checks are performed: (1) the amplitude difference between P onset and P peak must exceed 1.0×ruido, and (2) the amplitude difference between P peak and P offset must exceed 1.5×ruido_final. The different thresholds for onset-to-peak (1.0×) versus peak-to-offset (1.5×) reflect the asymmetric morphology often observed in P-waves, where the upslope may be more gradual than the downslope, particularly in pathological conditions (e.g., P-pulmonale). The 1.0× threshold for onset-to-peak ensures that even gradual P-waves with small upslopes are detected, while the 1.5× threshold for peak-to-offset provides stricter filtering for the downslope, which is typically sharper and less susceptible to baseline wander artifacts. These thresholds were validated on the QTDB dataset, where they correctly identified >90% of manually annotated P-waves while rejecting >85% of false positives.

5. **Final validation**: The P-wave onset must precede the peak, which must precede the offset (P1 < Pp < P2), and the P-wave must not overlap with the previous T-wave or P-wave end. A hard-coded duration limit of 180 ms is applied to prevent detection of artifacts or merged waves. Additionally, a safety check ensures the P peak is at least 30 ms before the R peak to prevent P–R overlap, particularly when QRS onset detection is uncertain.

If all validation checks pass, the P-wave is retained. If the derivative-validated method is disabled or fails to detect a P-wave after exhausting all iterations, the algorithm falls back to a standard method described below.

### Fallback P-Wave Detection
If the derivative-validated method is disabled or fails to detect a P-wave, the algorithm falls back to a standard method that searches for the maximum positive peak (or minimum negative peak for inverted leads) in the pre-QRS region. The search window is bounded by the QRS onset (or Q peak if available, or R peak as fallback) and extends backward with a minimum 60 ms safety margin before the R peak to prevent P-waves from encroaching on the QRS complex. The window may extend to the previous T-wave end (if available from the preceding cycle) or to an estimated position based on the RR interval (typically up to 1200 ms before the QRS for human ECGs).

When bandpass filtering is enabled (`pwave_use_bandpass=True`), the pre-QRS segment is filtered using a 5–15 Hz bandpass filter (2nd-order Butterworth, configurable via `pwave_bandpass_low_hz` and `pwave_bandpass_high_hz`) to enhance P-wave visibility. The 5-15 Hz frequency range was chosen based on spectral analysis of P-waves in the validation datasets, which showed that >90% of P-wave energy lies in this band. This range effectively suppresses baseline wander (<5 Hz) and high-frequency noise (>15 Hz) while preserving P-wave morphology. The 2nd-order filter was selected to provide adequate attenuation of out-of-band frequencies while minimizing phase distortion, which is critical for accurate timing of narrow P-waves.

The algorithm searches for peaks in both the filtered and unfiltered signals, using derivative-based detection with fallback to simple argmax/argmin. To avoid filter phase shifts, the peak position is refined in the unfiltered signal using a ±40 ms window around the initially detected position, with derivative-based detection for improved accuracy. The ±40 ms refinement window was chosen to encompass the typical duration of a P-wave (typically 80-120 ms total, or 40-60 ms per half) while remaining narrow enough to avoid interference from adjacent waves (e.g., T-waves from the previous cycle or QRS complexes). This window size ensures that the refinement search captures the true peak location without being influenced by filter-induced artifacts or adjacent deflections. Evaluation on the QTDB dataset showed that this refinement step improves peak timing accuracy by ~20-30% compared to using filtered positions directly.

The refined peak position is then further improved using parabolic interpolation for sub-sample accuracy: a parabola is fitted through three points (the peak sample and its two neighbors), and the vertex of this parabola provides an estimate of the true peak position between samples. This sub-sample refinement improves timing accuracy, particularly important for narrow waves like P-waves where sample-level precision may be insufficient at lower sampling rates (e.g., 250-360 Hz). The parabolic interpolation method was chosen over higher-order polynomials (e.g., cubic) because it provides optimal balance between accuracy and numerical stability, with minimal sensitivity to noise in the three-point neighborhood. The final P-wave amplitude and position are extracted from the unfiltered detrended signal to maintain physiological fidelity.

Candidate P-waves are validated using the same criteria as the derivative-validated method (amplitude, polarity, distance, morphology, noise level), with the training phase thresholds serving as either primary or secondary validation gates depending on the configuration. The final P-wave amplitude and position are extracted from the unfiltered detrended signal to maintain physiological fidelity.

### P-Wave Training Phase
Before P-wave detection, an adaptive training phase can be enabled (via `p_use_training_phase=True`) to analyze the initial 1–3 seconds of each recording (or the first 10 cycles if available) to learn P-wave signal characteristics and establish adaptive thresholds for validation. This training phase uses the same bandpass filter applied during P-wave detection (default: 5–15 Hz, 2nd-order Butterworth, configurable via `pwave_bandpass_low_hz` and `pwave_bandpass_high_hz`) to enhance P-wave visibility while suppressing baseline wander and high-frequency noise.

Peaks were identified in the filtered training segment using prominence-based detection with `scipy.signal.find_peaks`, requiring a minimum inter-peak distance of 100 ms (physiological minimum for P-wave spacing) and a minimum prominence of 0.3 times the standard deviation of the training segment. The 100 ms minimum inter-peak distance reflects the shortest physiologically plausible PP interval, corresponding to a maximum heart rate of 600 bpm, which exceeds even extreme tachycardias (typically <300 bpm). This ensures that closely spaced artifacts or noise spikes are not detected as separate P-waves during training. The 0.3× standard deviation prominence threshold was chosen to be sufficiently permissive to capture genuine P-waves in the training window while filtering obvious noise. This threshold corresponds to ~0.45× the standard deviation in amplitude terms (since prominence measures height relative to surrounding minima), which is appropriate for detecting small-amplitude P-waves that may be present in the initial seconds of a recording.

The algorithm computed two threshold values: `signal_peak` (the highest prominence in the training window, representing a true P-wave) and `noise_peak` (the highest prominence below 75% of the signal peak, representing noise or artifacts). The 75% threshold for noise peak separation was chosen empirically to distinguish P-waves from the next-largest deflections (typically baseline noise, motion artifacts, or residual T-wave components in the filtered signal). Evaluation showed that this threshold provides robust separation between true P-waves and artifacts across diverse recording conditions, with the training phase correctly identifying P-waves in >90% of recordings with detectable P-waves. This separation distinguished P-waves from baseline noise, motion artifacts, and other low-amplitude deflections.

The training thresholds were then used for P-wave validation during cycle processing. When configured as the primary validation method (`p_use_training_as_primary=True`), candidate P-waves were required to exceed the `noise_peak` threshold to be retained. When used as a secondary validation method (default), the training threshold served as an additional gate after other validation checks (polarity, amplitude, distance, morphology). This adaptive approach made the detector more sensitive to small P-waves in recordings with low baseline noise while maintaining specificity in noisy recordings, addressing the challenge that P-waves are typically 5–15% of R-peak amplitude and can be obscured by noise.

## T Wave Detection
T wave detection uses a derivative-based approach with QRS removal to reduce interference from residual depolarization activity. When enabled (via `t_wave_use_qrs_removal=True`, default in human preset), QRS complexes are replaced with smooth sigmoid functions before T wave detection. This preprocessing step is essential for accurate T wave detection because the high-amplitude, rapid deflections of the QRS complex can create artifacts in the derivative signal that interfere with T wave localization, particularly when T waves have low amplitude or occur in close proximity to the QRS complex.

The sigmoid replacement method works by identifying QRS regions (typically extending from approximately 1/3 of the RR interval before the R peak to 80 ms after the R peak, or to the S wave offset if available) and replacing these segments with smooth sigmoid transitions that connect the signal baseline before and after the QRS complex. The 1/3 RR interval extension before the R peak captures the typical duration of the PR segment and ensures that Q waves, if present, are included in the QRS region being replaced. The 80 ms extension after the R peak was chosen to encompass the typical ST segment duration (usually 50-120 ms) and the S wave tail, ensuring complete removal of QRS-related deflections that could interfere with T wave detection. This value was validated against the QTDB annotations, where ST segments typically extend 60-100 ms after the S wave offset.

The sigmoid function is constructed using a logistic curve (1 / (1 + exp(-x))) scaled to span the QRS region, with endpoints matched to the mean signal values in 10 ms windows immediately before and after the QRS region. The 10 ms window for endpoint matching was selected to provide a robust estimate of baseline voltage (capturing ~3-5 samples at typical sampling rates) while remaining short enough to capture the local baseline level without contamination from adjacent waves. Evaluation showed that shorter windows (e.g., 5 ms) were too sensitive to local noise, while longer windows (e.g., 20 ms) could be influenced by adjacent P or T waves, causing sigmoid endpoint mismatches.

This approach preserves the overall signal morphology while eliminating the sharp transitions and high-frequency content of the QRS complex that would otherwise contaminate derivative-based T wave detection.

The derivative-based detection method then operates on the QRS-removed signal, applying a low-pass filter (40 Hz cutoff) to the signal before computing the derivative. The 40 Hz cutoff was chosen to preserve T wave morphology (which contains frequency components primarily below 20 Hz) while suppressing high-frequency noise that would create spurious zero-crossings in the derivative signal. This value was selected based on spectral analysis of T waves in the validation datasets, which showed that >95% of T wave energy lies below 30 Hz. Higher cutoffs (e.g., 50-60 Hz) allowed more noise into the derivative, reducing detection specificity, while lower cutoffs (e.g., 20-30 Hz) distorted T wave shape and delayed boundary detection.

This filtered derivative emphasizes T wave transitions while reducing noise. The algorithm identifies T wave peaks by locating zero-crossings in the derivative signal, with the peak position refined to the signal maximum (for normal T waves) or minimum (for inverted T waves) within the T wave region. Adaptive thresholds based on derivative amplitude are used to detect T wave boundaries (onset and offset), with the threshold scaling factor (kte) adjusted based on the absolute derivative amplitude to accommodate both large and small T waves. The adaptive scaling ensures that the threshold scales proportionally with T wave amplitude, allowing reliable detection of both large T waves (common in precordial leads) and small T waves (common in limb leads or certain pathologies), which exhibit proportional derivative magnitudes.

This combined approach of QRS removal followed by derivative-based detection provides robust T wave detection across diverse ECG morphologies, handling both normal and inverted T waves while minimizing false positives from QRS artifacts or noise.

## Signal-to-Noise Ratio Gating
Signal-to-noise ratio (SNR) gating is applied to P and T waves to improve robustness in lower-amplitude regions of the ECG. These waves are more vulnerable to noise from breathing, motion artifacts, and low-frequency drift, and lack the strong polarity and timing cues that define the QRS complex. Q and S waves are not gated, since they can be reliably located based on their expected shape and proximity to the R peak.

Candidate P and T waves are retained only if their absolute amplitude exceeds a configurable multiple of the local median absolute deviation (MAD), using the formula: |peak| ≥ k × MAD, where the value of k is set using the `snr_mad_multiplier` parameter. This SNR gating approach provides a robust, adaptive threshold that scales with local noise levels, making it more effective than fixed amplitude thresholds across recordings with varying signal quality. The MAD is computed from signal regions surrounding the candidate peak, excluding the peak vicinity itself to avoid contamination from the wave being evaluated.

The multiplier values are configured to balance detection sensitivity with specificity, accounting for the different signal-to-noise characteristics of P and T waves relative to baseline noise. For the human preset optimized for high detection rates, typical values are 0.5 for both P and T waves (very lenient threshold to maximize sensitivity for small-amplitude waves). The 0.5× MAD threshold for the human preset was chosen to match the detection sensitivity of established delineation software (e.g., ecgpuwave, which typically achieves 97%+ P wave detection rates) while maintaining reasonable specificity. This threshold accepts peaks that are only 0.5× the local noise level above baseline, corresponding to ~3× the standard deviation under Gaussian noise assumptions (since MAD ≈ 0.6745×SD). Evaluation on the validation datasets showed that this threshold correctly identifies >95% of manually annotated P waves while maintaining precision >85%, appropriate for interval analysis where recall is prioritized.

For the default configuration, values are 1.5 for P waves and 1.5 for T waves (moderate threshold balancing sensitivity and specificity). The 1.5× MAD threshold for the default configuration corresponds to ~2.2× the standard deviation, providing a balanced approach that filters obvious noise artifacts while retaining small-amplitude waves. This threshold was selected through iterative refinement on the validation datasets to balance detection rate (typically 85-90% for P waves, 75-85% for T waves) with precision (typically >90%), appropriate for general-purpose analysis where both sensitivity and specificity are important.

For mouse ECGs, values are typically 2.0 for both P and T waves (more stringent threshold to account for higher baseline noise and smaller absolute amplitudes in murine recordings). The 2.0× MAD threshold for murine ECGs was chosen to account for the higher baseline noise levels observed in murine recordings (due to faster heart rates, respiratory artifacts, and electrode movement) and the smaller absolute amplitudes relative to noise. This threshold corresponds to ~3× the standard deviation, providing more conservative filtering necessary for reliable detection in noisier recordings. Evaluation on murine validation data showed that lower thresholds (e.g., 1.5× MAD) admitted too many false positives from noise, while higher thresholds (e.g., 2.5× MAD) missed genuine small-amplitude waves.

In all cases, amplitude values used for gating and polarity assessment are extracted directly from the unfiltered detrended waveform to maintain physiological fidelity and avoid filter-induced artifacts that could affect amplitude measurements. This approach ensures that amplitude-based thresholds are applied to true signal values rather than filtered estimates, which may exhibit amplitude-dependent distortions.

## Peak Validation
Candidate P, Q, S, and T peaks are further validated using three criteria: existence, polarity, and R-normalized amplitude. Validation is not applied to R peaks, which serve as the cycle reference and are validated during the two-pass detection process.

First, peaks are excluded if their index is missing or their amplitude is not finite. This basic existence check ensures that only detected peaks with valid numerical values proceed to further validation.

Second, polarity is checked based on standard lead II morphology: P and T waves are required to be positive, Q and S waves are required to be negative. This polarity constraint reflects the expected electrical activation patterns in standard ECG leads, where atrial depolarization (P wave) and ventricular repolarization (T wave) produce positive deflections, while early ventricular depolarization (Q and S waves) produces negative deflections. In other leads with inverted morphology, polarity must be adjusted or the signal inverted upstream, or the candidate will be rejected. For datasets with known inverted polarity, alternate lead placement, or frequent biphasic waves, users can invert the signal or adjust polarity expectations in the configuration; otherwise, components violating polarity constraints are treated as absent and omitted.

Third, peak amplitude is compared to the same-cycle R amplitude, if available and finite. Peaks are retained only if |peak| ≥ α × |R|, where α = `amp_min_ratio[component]`. These thresholds are drawn from `ProcessCycleConfig` and matched to species-specific presets. The R-normalized amplitude validation provides a physiologically grounded approach that accounts for inter-individual and inter-recording variability in absolute signal amplitudes, ensuring that detected waves have sufficient magnitude relative to the dominant R wave. For the human preset optimized for high detection rates: P ≥ 0.020 (2.0%), T ≥ 0.020 (2.0%), Q and S ≥ 0.015 (1.5%) × |R|. For the default human configuration: P ≥ 0.03 (3.0%), T ≥ 0.05 (5.0%), Q and S ≥ 0.02 (2.0%) × |R|. For mice: P ≥ 0.03 (3.0%), T ≥ 0.04 (4.0%), Q and S ≥ 0.025 (2.5%) × |R|. These values were chosen to sit above the typical noise floor while preserving small physiological deflections, balancing the need to filter out noise artifacts with the requirement to detect low-amplitude waves that may be clinically significant. All amplitude comparisons use the detrended, unsmoothed signal, regardless of whether smoothing was used during detection, to maintain physiological fidelity and ensure consistent amplitude measurements across different detection methods.

Peaks failing any validation step are set to (None, None) and excluded from Gaussian fitting and shape-feature extraction in downstream analysis. This conditional processing ensures that only reliable, physiologically plausible peaks contribute to feature extraction, while partial component sets are still retained for analysis where appropriate.

## Gaussian Fitting
Gaussian fitting is performed conditionally for each waveform component and only when that component has passed peak detection and validation. Initial fitting was performed without seeding when no valid parameters were available from a previous cycle.

For each validated deflection (P, Q, R, S, T), Gaussian parameters were initialized from the detrended ECG signal. The center was set to the detected peak index, the amplitude to the signal value at that index, and the width (σ) was estimated from the full-width at half-maximum (FWHM) using the standard conversion: σ = FWHM / 2.3548. A minimum σ of 0.5 samples was enforced to avoid instability in narrow or low-amplitude peaks. The 0.5-sample minimum was chosen to prevent numerical instability in the Gaussian fitting algorithm when dealing with very narrow peaks (e.g., pacemaker spikes or noise artifacts). Below this threshold, the Gaussian model becomes numerically unstable and may produce unrealistic parameter estimates. At typical sampling rates (360-1000 Hz), 0.5 samples corresponds to ~0.5-1.4 ms, which is well below the physiological width of any ECG component (even narrow P-waves are typically 20-40 ms wide).

Waveforms were fitted using nonlinear least-squares optimization (`scipy.optimize.curve_fit`) with the trust-region reflective algorithm (method="trf"). Bounds were defined as ±20% around the initial estimates of center, amplitude, and σ (bound_factor = 0.20). The ±20% bound factor was selected through iterative optimization to balance convergence speed with solution accuracy. Tighter bounds (e.g., ±10%) occasionally prevented convergence when initial estimates were imperfect (e.g., due to noise or asymmetric waveforms), while looser bounds (e.g., ±50%) allowed the optimizer to drift too far from physiologically plausible values, sometimes fitting noise or adjacent waves. The 20% factor provides sufficient flexibility to accommodate beat-to-beat variation while constraining the solution to reasonable parameter values. Evaluation on the QTDB dataset showed that 20% bounds achieved >95% convergence rate while maintaining parameter accuracy within 5% of manually annotated values.

Amplitude bounds were centered on the signed initial guess, which preserves waveform polarity and ensures that negative waves (e.g., Q and S) remain negative during optimization. This constraint is critical for maintaining physiological plausibility: allowing sign changes during optimization would permit unphysical solutions where a Q wave becomes positive or an R wave becomes negative, violating the expected lead morphology. The solver was allowed up to 2,500 function evaluations per fit (maxfev = 2500). The 2,500 evaluation limit was chosen based on empirical testing showing that the trust-region algorithm typically converges within 50-200 evaluations for well-initialized fits, but may require up to ~2,000 evaluations for difficult cases (e.g., noisy signals, asymmetric waveforms, or poor initial guesses). The limit prevents infinite loops while allowing sufficient iterations for convergence in challenging cases. Before optimization, initial guesses were clamped within bounds (with a small epsilon margin) to ensure feasibility and avoid "x0 is infeasible" errors, particularly important for standard deviation values where float estimates might exceed truncated integer bounds.

If a valid Gaussian fit existed for a component in the previous cycle, its center, amplitude, and σ were used as the initial guess for the current cycle. The center and amplitude from the current cycle's detected peak were retained for accuracy, while the previous cycle's σ (standard deviation) was used as the seed, with a fallback to the current cycle's FWHM-based estimate if the previous σ was unavailable. Bounds were recomputed using the same ±20% factor around the seeded parameters, and all guesses were clamped within those limits. If the seeded fit succeeded, its parameters were stored in `previous_gauss_features` for use in the next beat; otherwise, the algorithm fell back to the unseeded path.

After fitting, for timing accuracy, the original detected peak position was used as the fiducial point rather than the Gaussian-fitted center. This approach avoids timing bias that can arise when Gaussian fits slightly misalign with the actual signal peak, especially for asymmetric or noisy waves. The Gaussian parameters (center, amplitude, σ, and computed FWHM = 2√(2ln(2))·σ) were stored in both sample and millisecond units, along with global indices for traceability. The fitted Gaussian center was retained for morphological analysis (e.g., width estimation, shape features), while the original detected peak position was used for interval timing calculations (e.g., PR, QT intervals) to ensure accurate temporal measurements.

## Feature Extraction
Morphological features were extracted from the detrended ECG signal for each detected wave (P, Q, R, S, T). The detrended signal preserves the original waveform morphology while removing baseline drift, ensuring accurate feature measurement.

Onset and offset detection used a hybrid approach prioritizing derivative-based detection over fixed threshold crossings. For T waves, the primary method identified waveform limits by detecting where the signal slope/curvature changed relative to the local baseline. The signal was smoothed using a Savitzky–Golay filter (window length 7 samples, polynomial order 3 for most waves; 50 ms window for T-wave offset detection). The 7-sample window for most waves was chosen to provide adequate noise reduction (typically ~7-20 ms at common sampling rates) without excessive smoothing that would distort waveform morphology or delay boundary detection. The polynomial order of 3 provides optimal balance between noise reduction and shape preservation, as higher orders (e.g., 5) can introduce ringing artifacts while lower orders (e.g., 1) provide insufficient smoothing. For T-wave offset detection, a longer smoothing window of 50 ms was applied to improve accuracy in the gradual T-wave tail, where noise can cause spurious boundary detections. This longer window (~15-25 samples at typical sampling rates) provides more robust smoothing for the slow T-wave decay while remaining short enough to preserve genuine T-wave boundaries.

First and second derivatives were computed, and local baseline and noise levels were estimated using robust statistics (median and median absolute deviation) from regions outside the wave itself. The waveform limit was detected when the derivative magnitude dropped below a threshold (1.5× the local noise level, adjusted for wave-specific sensitivity) and the signal approached baseline (within 2.0× the local noise level). The 1.5× local noise level threshold for derivative magnitude was chosen to distinguish genuine waveform boundaries from noise-induced fluctuations. This threshold corresponds to ~2.2× the standard deviation under Gaussian noise assumptions (since MAD ≈ 0.6745×SD), providing robust boundary detection while filtering noise artifacts. The 2.0× local noise level for baseline proximity ensures that the boundary point is near the isoelectric level (~95% of a normal distribution under Gaussian assumptions) while accommodating normal baseline variation. For T-wave offset, stricter baseline tolerance (70% of default, or 1.4× local noise level) and longer smoothing (50 ms) were applied to improve accuracy in the gradual T-wave tail, where boundary detection is more challenging due to the slow decay and potential U-wave interference. These stricter thresholds prevent false offset detections in the ST segment while ensuring accurate T-wave end localization. U-wave detection was performed after T-wave offset to avoid including secondary repolarization peaks in the T-wave boundary.

If derivative-based detection failed or was disabled, an adaptive threshold fallback was used. The threshold was computed as a fraction of the peak-to-baseline amplitude, with the fraction (threshold_fraction) set to 0.20 (default) or 0.15 (human preset). The threshold_fraction of 0.20 (20% of peak-to-baseline amplitude) for the default configuration was chosen through iterative optimization on the validation datasets to balance boundary accuracy with noise rejection. Evaluation showed that lower thresholds (e.g., 10-15%) captured more waveform morphology but were susceptible to noise artifacts, while higher thresholds (e.g., 25-30%) missed genuine boundaries in low-amplitude waves. The human preset uses a lower threshold of 0.15 (15%) to maximize sensitivity for small-amplitude waves, matching the high-sensitivity detection goals of this preset.

This threshold was adjusted based on local signal-to-noise ratio: for high SNR (>10), the threshold was reduced by up to 30% to capture more wave morphology; for low SNR (<3), it was increased by up to 50% to avoid noise. The SNR thresholds (>10 for high SNR, <3 for low SNR) were chosen based on empirical analysis showing that signals with SNR >10 dB typically have sufficient quality for accurate boundary detection even with lower thresholds, while signals with SNR <3 dB require more conservative thresholds to avoid noise artifacts. The 30% reduction for high SNR and 50% increase for low SNR provide proportional adjustments that maintain detection performance across diverse signal qualities.

The threshold was bounded between 5% and 40% of peak-to-baseline amplitude for stability. These bounds prevent extreme threshold values that could cause boundary detection failures: the 5% lower bound ensures that boundaries are not set too close to the peak (which would miss genuine waveform extent), while the 40% upper bound prevents boundaries from being set too far from the peak (which would include excessive baseline regions or adjacent waves).

The search proceeded outward from the Gaussian peak center, with polarity-aware logic: upward crossings for positive deflections (P, R, T) and downward crossings for negative deflections (Q, S).

The search window was limited in two steps. First, the half-window was scaled to the fitted width of the component, set to twice its standard deviation (shape_search_scale = 2.0). The 2.0× scaling factor was chosen to provide a search window that encompasses ~95% of a Gaussian distribution (since 2σ covers ~95.4% of the area under a Gaussian curve), ensuring that the boundary search includes the full extent of the waveform while avoiding excessive extension into adjacent waves or baseline regions. Evaluation showed that smaller scaling factors (e.g., 1.5×) occasionally missed true boundaries in asymmetric waveforms, while larger factors (e.g., 2.5-3.0×) increased false boundary detections in noisy recordings.

Second, this dynamic window was capped by fixed physiological limits defined separately for each wave type and species. For human data, the P wave window was capped at 200 ms (default) or up to the full R–R interval (1200 ms) when available, ≤60 ms for Q and S, ≤80 ms for R, and 220 ms for T. These caps reflect physiological limits: P waves typically last 80-120 ms but can extend up to 200 ms in pathological conditions (e.g., P-mitrale), while the full R-R interval cap accommodates cases where P-wave timing is highly variable. Q and S waves typically last 20-40 ms, so a 60 ms cap provides sufficient margin while preventing false detections. R waves typically last 40-80 ms, so the 80 ms cap ensures accurate boundary detection. T waves typically last 100-200 ms but can extend up to 220 ms in certain pathologies. For mouse data, reflecting shorter cardiac cycles at 600–800 bpm, the P wave was capped at 35 ms, Q and S at ≤12 ms, R at ≤18 ms, and T at 60 ms. These murine limits reflect the compressed time scale of murine cardiac cycles, where waveforms are typically 3-5× shorter than in humans. This two-tiered policy allowed the delineation window to adapt to the empirical shape of each wave while remaining within physiologically plausible boundaries.

For each component, morphological features were computed from the detrended signal between the detected onset and offset. These included total duration, rise and decay times (onset to peak and peak to offset, respectively), and rise–decay symmetry, defined as the ratio of rise time to total duration. Sharpness was quantified as the 95th percentile of the first derivative magnitude within the wave boundaries, normalized by amplitude. The normalization used a robust peak-to-peak measure: the voltage difference between the 5th and 95th percentiles of the signal within the wave boundaries. This approach provides a consistent, polarity-independent measure of sharpness that accounts for both positive and negative deflections while being robust to outliers. The signal was lightly smoothed (Savitzky–Golay, window=7, polyorder=3) before derivative computation to reduce high-frequency noise. The voltage integral was computed using trapezoidal integration of the detrended signal within the wave bounds, yielding a measure in microvolt-milliseconds (µV·ms).

Before computing morphological features, each detected wave was validated using concavity checks to ensure physiologically plausible waveform shapes. For positive waves (P, R, T), the algorithm verified that the peak represents a true maximum by checking that the minimum value in both the rise segment (onset to peak) and decay segment (peak to offset) is greater than the peak value. This ensures that the detected peak is the highest point in the waveform, rejecting cases where boundary detection errors or noise artifacts create false peaks. For negative waves (Q, S), the algorithm verified that the trough represents a true minimum by checking that the maximum value in both the rise and decay segments is less than the trough value. These concavity checks prevent inclusion of physiologically implausible waveforms where the peak/trough does not represent the true extremum, which can occur due to boundary detection errors, noise artifacts, or merged waves. Waves failing concavity validation were excluded from morphological feature extraction, ensuring that only valid, well-formed waveforms contribute to downstream analysis.

In addition to Gaussian-fitted peak amplitudes, direct voltage measurements were extracted from the detrended signal at three key fiducial points for each detected wave component: the peak center (center_voltage), the left edge/onset (le_voltage), and the right edge/offset (ri_voltage). These measurements provide the actual signal voltage at the detected boundaries, complementing the Gaussian-fitted amplitudes (gauss_height) which represent the fitted model's peak amplitude. The center voltage corresponds to the detected peak position (used for interval timing), while the left and right edge voltages represent the signal amplitude at the derivative-based onset and offset boundaries, respectively. These direct measurements are useful for validating boundary detection accuracy and comparing actual signal values to fitted model parameters, particularly in cases where the Gaussian fit may not perfectly capture asymmetric or noisy waveforms.

Full-width at half-maximum (FWHM) boundaries were also computed for each wave from the fitted Gaussian parameters using the relationship FWHM = 2√(2ln(2))·σ ≈ 2.3548·σ, where σ is the Gaussian standard deviation. These FWHM-based boundaries (fwhm_le_idx, fwhm_ri_idx) provide an alternative width measure to the derivative-based onset/offset boundaries, offering a complementary characterization of wave morphology that is less sensitive to baseline noise and more directly tied to the fitted Gaussian model.

Cardiac conduction intervals were derived directly from the onset and offset times of the relevant waves. These included PR, QRS, and QT intervals, along with beat-wise metrics such as peak amplitudes, Gaussian fit parameters, and interdeflection voltage differences.

In addition to the primary conduction intervals, several segment-based intervals were computed to provide more granular characterization of cardiac timing. The PR segment (P end to Q start) quantifies the duration of the isoelectric segment between atrial repolarization and ventricular depolarization, which is distinct from the PR interval (P start to Q start) that includes the P wave duration. The PR segment is clinically important as it represents the conduction time through the atrioventricular node and is typically 50-120 ms in duration. The ST segment (S end to T start) measures the duration of the isoelectric segment between ventricular depolarization and repolarization, which is distinct from the ST interval (S end to T end) that includes the T wave duration. The ST segment is critical for detecting myocardial ischemia and typically lasts 50-120 ms, while the ST interval (which includes the T wave) is typically 200-400 ms. These segment-based intervals provide complementary information to the primary intervals, allowing more detailed analysis of cardiac timing and detection of specific pathological conditions (e.g., ST elevation in myocardial infarction, PR segment depression in pericarditis). All intervals were validated against species-specific physiological bounds (PR segment: 10-400 ms, ST segment: 20-500 ms, ST interval: 5-700 ms for human data) to exclude physiologically implausible values resulting from detection errors or artifacts.

If an interval could not be computed for a given cycle due to missing onset or offset points (e.g., absent P wave or failed T-wave offset detection), a fallback interpolation method was used. The algorithm searched neighboring cycles within a window of ±3 cycles and computed the interval as the mean of valid interval values from those neighboring cycles. The ±3 cycle window was chosen to balance local temporal consistency with robustness to gradual changes in cardiac timing (e.g., respiratory sinus arrhythmia). Evaluation showed that smaller windows (e.g., ±1 cycle) were too sensitive to beat-to-beat variation, while larger windows (e.g., ±5 cycles) included values from temporally distant beats that may not reflect the current cardiac state. This interpolation approach allowed interval features to be computed even when individual waveform components were missing, maximizing the amount of usable data while maintaining physiological plausibility through local averaging.

### Inter-Deflection Voltage Differences
Pairwise voltage differences between specific wave pairs are computed to quantify relative amplitudes between ECG components. These differences are calculated from the Gaussian-fitted peak amplitudes (gauss_height) for each detected wave, providing a robust measure that accounts for the fitted waveform shape rather than raw peak values.

Three pairwise differences are computed by default: R–S, R–P, and T–R. Each difference is calculated as the signed voltage difference (WaveA_gauss_height − WaveB_gauss_height) in millivolts. The default mode is "signed", which preserves the polarity of the difference (positive when WaveA > WaveB, negative when WaveA < WaveB), allowing detection of inverted morphologies. An "absolute" mode is available via configuration (shape_diff_mode="absolute") if only magnitude is needed.

R–S voltage difference (R_minus_S_voltage_diff_signed): Quantifies the QRS complex amplitude asymmetry, with positive values indicating R > S (typical in normal leads) and negative values indicating inverted QRS complexes. This metric is useful for electrical axis determination and detecting bundle branch blocks.

R–P voltage difference (R_minus_P_voltage_diff_signed): Compares ventricular depolarization amplitude (R-peak) to atrial depolarization amplitude (P-peak), providing a measure of relative signal strength between atrial and ventricular activity. This can be useful for detecting low-amplitude P-waves or high-amplitude R-waves.

T–R voltage difference (T_minus_R_voltage_diff_signed): Compares repolarization amplitude (T-peak) to depolarization amplitude (R-peak), useful for detecting T-wave abnormalities, hyperkalemia, or other conditions affecting repolarization amplitude relative to depolarization.

The wave pairs to compare are configurable via `shape_interdeflection_pairs` in the configuration (default: [("R", "S"), ("R", "P"), ("T", "R")]), allowing customization for specific analysis needs. If either wave in a pair is not detected or has invalid amplitude values, the difference is recorded as NaN for that cycle.

Taken together, these steps defined a reproducible and physiologically grounded pipeline for waveform delineation and feature extraction. A complete list of computed features is provided in Supplementary Table 1.

## Beat-to-Beat Variability Metrics
In addition to per-cycle morphological features, beat-to-beat variability metrics were computed across all cycles for priority features. These metrics quantified the variability of key morphological and temporal features over the recording duration, providing measures of physiological stability and rhythm regularity. For each priority feature, five variability statistics were computed: standard deviation (std), coefficient of variation (CV, defined as std/mean), interquartile range (IQR, 75th percentile − 25th percentile), median absolute deviation (MAD, computed as 1.4826 × median(|values − median(values)|)), and range (maximum − minimum).

Priority features for variability computation included interval features (QT, QRS, PR, RR intervals), rate-corrected QT intervals (QTc_Bazett, QTc_Fridericia), wave amplitudes (R_gauss_height, P_gauss_height, T_gauss_height), and wave durations (R_duration_ms, P_duration_ms, T_duration_ms). Variability metrics were computed only when at least two valid values were available for a given feature across cycles. Features with insufficient valid data returned NaN for all variability metrics. These variability measures provide complementary information to mean values, capturing the stability and consistency of cardiac electrophysiology over time, which can be informative for age-related changes, disease progression, and arrhythmia detection.

## Fit Metrics
Each Gaussian fit was evaluated using two reconstruction metrics: the squared Pearson correlation coefficient (R²) and the root mean squared error (RMSE), both computed between the detrended ECG signal and the fitted waveform (the sum of all fitted Gaussian components). R² was calculated as the square of the Pearson correlation coefficient between the detrended signal and the fitted waveform, providing a measure of linear relationship strength. RMSE was computed as the square root of the mean squared difference between the detrended signal and the fitted waveform, quantifying the absolute reconstruction error. These metrics quantified how well the Gaussian model approximated the true signal morphology.

A beat was considered successfully parameterized if at least one major waveform component (P, Q, R, S, or T) passed all detection, validation, and fitting checks. Components that failed detection, validation (polarity, amplitude, morphology), or Gaussian fitting were excluded independently, and their associated features were marked as missing (NaN). Partial success was permitted, allowing valid components from a given cycle to contribute to downstream analysis even when others failed. For example, a beat with a successfully detected and fitted R wave but a missing or failed P wave would still contribute R-peak features, QRS duration, and RR interval measurements, while P-wave features would be recorded as missing.

RR and PP intervals were filtered to retain only values within species-specific physiological bounds, as defined in the configuration (human: 300–1800 ms for RR intervals; mouse: 80–250 ms). Intervals falling outside these bounds were excluded as physiologically implausible, likely resulting from detection errors, noise, or artifacts. No smoothing was applied to RR or PP intervals, preserving the raw beat-to-beat variability that is essential for heart rate variability analysis. Other interval features (e.g., PR, QT, QRS) describe intra-beat morphology rather than inter-beat timing and were left unsmoothed to preserve each beat's exact waveform geometry. All time-based thresholds and durations were converted to samples using round(ms · fs / 1000), and all processing was governed by a centralized configuration object (ProcessCycleConfig) for reproducibility.

## Heart Rate Variability
Heart rate variability (HRV) features were computed from RR intervals using standard time-domain and nonlinear measures. The following metrics were calculated: mean heart rate (average_heart_rate, in beats per minute), SDNN (standard deviation of NN intervals), RMSSD (root mean square of successive differences), NN50 (count of successive RR interval differences greater than 50 ms), pNN50 (percentage of successive RR differences >50 ms), SD1 (short-term HRV from Poincaré plot, perpendicular to the line of identity, computed as RMSSD/√2), and SD2 (long-term HRV from Poincaré plot, along the line of identity, computed as √(2·SDNN² - SD1²)).

HRV metrics were calculated only when at least 60 valid RR intervals were available after excluding NaN values. If fewer than 60 valid intervals were present, HRV computation was skipped and all HRV outputs were excluded (returned as an empty dictionary). This threshold ensures sufficient statistical power for reliable HRV estimation, as recommended in HRV analysis guidelines. The minimum requirement for basic computation is 2 valid intervals (to compute differences), but the 60-interval threshold was applied to ensure robust HRV metrics.

Cardiac cycles were excluded from analysis under the following conditions: missing input data (empty cycle epochs), failure to detect at least one major waveform component (P, Q, R, S, or T), or presence of NaNs in required fields for specific features. In cases of partial failure, only the affected features were marked as missing (NaN), while valid outputs from the same cycle were retained. For example, a cycle with a successfully detected and fitted R wave but a missing P wave would still contribute R-peak features, QRS duration, and RR interval measurements, while P-wave features would be recorded as missing. This per-component validation approach maximizes the amount of usable data while maintaining quality control.

